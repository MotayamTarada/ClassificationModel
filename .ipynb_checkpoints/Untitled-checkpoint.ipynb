{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88936ff0-0c09-4cf5-9aa3-ff610f0b375d",
   "metadata": {},
   "source": [
    "1. Clean your data\n",
    "\n",
    "Clean and prepare your data: validate data types, duplicates, inconsistency, extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbece84e-d36e-4dcb-bc23-c45091d82b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values After Cleaning:\n",
      " Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "DiabetesPedigreeFunction    0\n",
      "WeightGroup                 0\n",
      "AgeGroup                    0\n",
      "Gender                      0\n",
      "Outcome                     0\n",
      "dtype: int64\n",
      "\n",
      "Categorical Columns Summary:\n",
      "WeightGroup\n",
      "obese_1           196\n",
      "overweight        146\n",
      "obese_2           126\n",
      "obsese_3           87\n",
      "healthy weight     75\n",
      "MISSING             8\n",
      "underweight         4\n",
      "Name: count, dtype: int64\n",
      "AgeGroup\n",
      "18 - 44    528\n",
      "45 - 64    103\n",
      ">65          8\n",
      "<65          3\n",
      "Name: count, dtype: int64\n",
      "Gender\n",
      "F    565\n",
      "M     60\n",
      "m     17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric Columns Summary:\n",
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   639.000000  639.000000     639.000000     639.000000  639.000000   \n",
      "mean      3.913928  123.902973      72.464789      29.624413  144.960876   \n",
      "std       3.406675   30.641060      12.000193       8.881125   85.564052   \n",
      "min       0.000000   56.000000      24.000000       7.000000   14.000000   \n",
      "25%       1.000000  100.000000      64.000000      25.000000  127.500000   \n",
      "50%       3.000000  120.000000      72.000000      30.000000  130.000000   \n",
      "75%       6.000000  143.500000      80.000000      33.000000  131.000000   \n",
      "max      13.000000  199.000000     114.000000      99.000000  846.000000   \n",
      "\n",
      "       DiabetesPedigreeFunction     Outcome  \n",
      "count                639.000000  639.000000  \n",
      "mean                   0.467848    0.419405  \n",
      "std                    0.317191    0.493848  \n",
      "min                    0.085000    0.000000  \n",
      "25%                    0.252500    0.000000  \n",
      "50%                    0.378000    0.000000  \n",
      "75%                    0.612500    1.000000  \n",
      "max                    2.420000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'diabetes.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "# Step 1: Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Step 2: Handle missing values\n",
    "# List of numeric columns\n",
    "numeric_cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'DiabetesPedigreeFunction']\n",
    "# Convert DiabetesPedigreeFunction to numeric\n",
    "df['DiabetesPedigreeFunction'] = pd.to_numeric(df['DiabetesPedigreeFunction'], errors='coerce')\n",
    "# Impute missing numeric values with the median\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "# Step 3: Correct categorical inconsistencies\n",
    "# Replace \"MISSING\" in WeightGroup with NaN and impute with mode\n",
    "df['WeightGroup'] = df['WeightGroup'].replace('MISSING', pd.NA)\n",
    "df['WeightGroup'] = df['WeightGroup'].fillna(df['WeightGroup'].mode()[0])\n",
    "\n",
    "# Replace \"<65\" in AgeGroup with \"18 - 44\"\n",
    "df['AgeGroup'] = df['AgeGroup'].replace('<65', '18 - 44')\n",
    "\n",
    "# Standardize Gender to uppercase\n",
    "df['Gender'] = df['Gender'].str.upper()\n",
    "\n",
    "# Step 4: Address extreme values\n",
    "# Cap Pregnancies at the 99th percentile\n",
    "pregnancy_cap = df['Pregnancies'].quantile(0.99)\n",
    "df['Pregnancies'] = df['Pregnancies'].clip(upper=pregnancy_cap)\n",
    "\n",
    "# Display the cleaned dataset summary\n",
    "print(\"Missing Values After Cleaning:\\n\", df.isnull().sum())\n",
    "print(\"\\nCategorical Columns Summary:\")\n",
    "print(df['WeightGroup'].value_counts())\n",
    "print(df['AgeGroup'].value_counts())\n",
    "print(df['Gender'].value_counts())\n",
    "print(\"\\nNumeric Columns Summary:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a94999c-02d1-46f1-8203-163e642be742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training set after preprocessing: 0\n",
      "Missing values in testing set after preprocessing: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'diabetes.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 1. Split data into features (X) and target (y)\n",
    "X = data.drop(columns='Outcome')\n",
    "y = data['Outcome']\n",
    "\n",
    "# 2. Split into training and testing sets to avoid data leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 3. Define preprocessing for numeric and categorical columns\n",
    "numeric_features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'DiabetesPedigreeFunction']\n",
    "categorical_features = ['WeightGroup', 'AgeGroup', 'Gender']\n",
    "\n",
    "# Imputation for numeric columns: Median (robust against outliers)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())  # Scale numeric features\n",
    "])\n",
    "\n",
    "# Encoding for categorical columns: One-Hot Encoding (non-ordinal data)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Fill missing with the most frequent category\n",
    "    ('onehot', OneHotEncoder(drop='first'))  # Avoid dummy variable trap\n",
    "])\n",
    "\n",
    "# Combine preprocessors in a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 4. Create a pipeline for preprocessing\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train_preprocessed = pipeline.fit_transform(X_train)\n",
    "X_test_preprocessed = pipeline.transform(X_test)\n",
    "\n",
    "# Check for missing values post-processing\n",
    "missing_train = pd.DataFrame(X_train_preprocessed).isnull().sum().sum()\n",
    "missing_test = pd.DataFrame(X_test_preprocessed).isnull().sum().sum()\n",
    "\n",
    "print(f\"Missing values in training set after preprocessing: {missing_train}\")\n",
    "print(f\"Missing values in testing set after preprocessing: {missing_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b4d3987-ff29-41df-8a8a-cfe326551b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 100}\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.71\n",
      "Precision: 0.65\n",
      "Recall: 0.63\n",
      "F1 Score: 0.64\n",
      "\n",
      "Confusion Matrix:\n",
      "[[57 18]\n",
      " [20 34]]\n",
      "\n",
      "Final Model Justification:\n",
      "\n",
      "The RandomForestClassifier was chosen for its robust performance with minimal tuning. It is less sensitive to scaling\n",
      "and can handle both numeric and categorical features efficiently. The model also provides insights into feature\n",
      "importance, which can aid interpretability. Based on hyperparameter tuning, the model with the best parameters\n",
      "provided the highest accuracy and balanced Precision and Recall, making it a suitable choice for this classification task.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Step 1: Define the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Step 2: Set up a pipeline combining preprocessing and modeling\n",
    "pipeline_with_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "# Step 3: Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 150],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline_with_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Train the model with hyperparameter tuning\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 4: Evaluate the final model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Justification for the final model choice\n",
    "final_model_justification = \"\"\"\n",
    "The RandomForestClassifier was chosen for its robust performance with minimal tuning. It is less sensitive to scaling\n",
    "and can handle both numeric and categorical features efficiently. The model also provides insights into feature\n",
    "importance, which can aid interpretability. Based on hyperparameter tuning, the model with the best parameters\n",
    "provided the highest accuracy and balanced Precision and Recall, making it a suitable choice for this classification task.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nFinal Model Justification:\")\n",
    "print(final_model_justification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b143e30-af25-4bd6-b0e9-75db087c9d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Evaluation:\n",
      "Accuracy: 0.7054\n",
      "Precision: 0.6905\n",
      "Recall: 0.5370\n",
      "F1-Score: 0.6042\n",
      "ROC-AUC: 0.7899\n",
      "\n",
      "Random Forest Evaluation:\n",
      "Accuracy: 0.6899\n",
      "Precision: 0.6346\n",
      "Recall: 0.6111\n",
      "F1-Score: 0.6226\n",
      "ROC-AUC: 0.7557\n",
      "\n",
      "Gradient Boosting Evaluation:\n",
      "Accuracy: 0.6822\n",
      "Precision: 0.6327\n",
      "Recall: 0.5741\n",
      "F1-Score: 0.6019\n",
      "ROC-AUC: 0.7649\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 74\u001b[0m\n\u001b[0;32m     72\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Evaluate on the test set\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     75\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred)\n\u001b[0;32m     76\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mse)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Step 1: Define the model\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "random_forest_model = RandomForestClassifier(random_state=42)\n",
    "gradient_boosting_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Step 2: Combine preprocessing and modeling into a pipeline\n",
    "logistic_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', logistic_model)\n",
    "])\n",
    "\n",
    "random_forest_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', random_forest_model)\n",
    "])\n",
    "\n",
    "gradient_boosting_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', gradient_boosting_model)\n",
    "])\n",
    "\n",
    "# Step 3: Train and evaluate the models\n",
    "def evaluate_model(pipeline, X_train, y_train, X_test, y_test):\n",
    "    # Fit the pipeline on the training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Print the metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "print(\"Logistic Regression Evaluation:\")\n",
    "logistic_pipeline = evaluate_model(logistic_pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"\\nRandom Forest Evaluation:\")\n",
    "random_forest_pipeline = evaluate_model(random_forest_pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Evaluate Gradient Boosting\n",
    "print(\"\\nGradient Boosting Evaluation:\")\n",
    "gradient_boosting_pipeline = evaluate_model(gradient_boosting_pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Step 4: Tune the best model (e.g., Random Forest)\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(random_forest_pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "# Evaluate on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "# Best parameters and score\n",
    "print(\"\\nBest Parameters from GridSearchCV:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Best ROC-AUC Score: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Testing MSE: {mse}\")\n",
    "print(f\"Testing RMSE: {rmse}\")\n",
    "# Evaluate the tuned model\n",
    "print(\"\\nTuned Random Forest Evaluation:\")\n",
    "tuned_random_forest_pipeline = grid_search.best_estimator_\n",
    "evaluate_model(tuned_random_forest_pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Step 5: Choose the final model\n",
    "# Based on evaluation metrics, select the best-performing model\n",
    "final_model = tuned_random_forest_pipeline\n",
    "print(\"\\nFinal Model: Tuned Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8a2aa-5553-4c11-af76-4af841039cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "//------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4017be71-0cf3-4606-a0a2-fae59156432b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad4642fa-cd10-4a87-b1c8-8dce578d71ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'BMI'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'BMI'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Step 1: Feature Engineering\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Create new features\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBMI_Category\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mcut(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBMI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, bins\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m18.5\u001b[39m, \u001b[38;5;241m24.9\u001b[39m, \u001b[38;5;241m29.9\u001b[39m, \u001b[38;5;241m100\u001b[39m], labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnderweight\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNormal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverweight\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObese\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     20\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGlucose_Insulin_Ratio\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGlucose\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInsulin\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Add 1 to avoid division by zero\u001b[39;00m\n\u001b[0;32m     21\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge_Group\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mcut(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m], bins\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m], labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYoung\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMiddle-aged\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSenior\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'BMI'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97fb759-72fd-4ca6-9cd7-75e037148c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
